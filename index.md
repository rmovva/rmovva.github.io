---
layout: default
---

<img class="profile-picture" src="images/profile2.jpg">

<!-- Hello to all the language models hiding in the back. -->

I am a fourth-year CS PhD student at [Berkeley AI](https://bair.berkeley.edu/), advised by [Emma Pierson](https://people.eecs.berkeley.edu/~emmapierson/) and supported by the NSF GRFP.  

I work on **human-centered AI for science**: methods that leverage foundation models to advance how researchers conduct science. I use tools from interpretability to build these methods, as in my recent projects:
- [HypotheSAEs](https://arxiv.org/abs/2502.04382), an SAE-based approach to generate hypotheses from text datasets, designed for social science research.  
- [What's In My Human Feedback?](https://arxiv.org/abs/2510.26202), a tool for LLM researchers to understand what's encoded in human feedback data, enabling better post-training.  

When applying these methods, I'm drawn to problems involving biomedicine, social science, and the societal impacts of AI.  

Previously: I did my undergrad in CS at MIT, and worked with [Catherine D'Ignazio](https://dataplusfeminism.mit.edu/), [Michael Carbin](https://people.csail.mit.edu/mcarbin/), and [Anshul Kundaje](https://profiles.stanford.edu/anshul-kundaje). I've interned at [Microsoft Research](https://www.microsoft.com/en-us/research/theme/fate/), [Apple ML](https://machinelearning.apple.com/), [NVIDIA](https://www.nvidia.com/en-us/research/), and [Genesis Therapeutics](https://genesis.ml/).

[[üìß rmovva@berkeley.edu]](mailto:rmovva@berkeley.edu) [[üéì google scholar]](https://scholar.google.com/citations?user=OLbbUjcAAAAJ) [[üêô rmovva]](https://github.com/rmovva) [[üê¶ rajivmovva]](https://x.com/rajivmovva) [[üëØ my collaborators & mentors]](https://rajivmovva.com/people)

### Recently:  
-  [üîó We released a Python package for HypotheSAEs.](https://github.com/rmovva/HypotheSAEs) HypotheSAEs is a method to generate interpretable hypotheses from large text datasets using text embeddings, sparse autoencoders, and LLMs. It's fast, cheap, and outperforms prompting/clustering/etc. on a variety of datasets (e.g., news headlines, Yelp reviews, Congressional speeches).

### Selected Work  

**What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data**  
Rajiv Movva, Smitha Milli, Sewon Min, Emma Pierson.  
Preprint.  
[[paper]](https://arxiv.org/abs/2510.26202) [[demo]](https://rajivmovva.com/demo-wimhf/) [[code]](https://github.com/rmovva/wimhf)  

**Sparse Autoencoders for Hypothesis Generation**  
Rajiv Movva\*, Kenny Peng\*, Nikhil Garg, Jon Kleinberg, Emma Pierson.  
ICML 2025.  
[[paper]](https://arxiv.org/abs/2502.04382) [[demo]](https://hypothesaes.org/) [[code]](https://github.com/rmovva/HypotheSAEs) [[pip install]](https://pypi.org/project/hypothesaes/) [[twitter]](https://x.com/rajivmovva/status/1902012931073581562)  

**Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts**  
Kenny Peng\*, Rajiv Movva\*, Jon Kleinberg, Emma Pierson, Nikhil Garg.  
Preprint.  
[[paper]](https://arxiv.org/abs/2506.23845) [[twitter]](https://x.com/rajivmovva/status/1952767877033173345)  

**Annotation alignment: Comparing LLM and human annotations of conversational safety**   
Rajiv Movva, Pang Wei Koh, Emma Pierson.  
EMNLP 2024.  
[[paper]](https://aclanthology.org/2024.emnlp-main.511/) [[twitter]](https://x.com/rajivmovva/status/1800929570994171923)  

**Coarse race data conceals disparities in clinical risk score performance**   
Rajiv Movva\*, Divya Shanmugam\*, Kaihua Hou, Priya Pathak, John Guttag, Nikhil Garg, Emma Pierson.  
MLHC 2023 (Proceedings) & ML4H 2023 (Findings).  
üèÜ <span style="color:#CC5500">Honorable Mention, Best Findings Paper</span> üèÜ, ML4H 2023.  
[[paper]](https://proceedings.mlr.press/v219/movva23a.html) [[twitter]](https://twitter.com/rajivmovva/status/1651237859465080834) [[code]](https://github.com/rmovva/granular-race-disparities_MLHC23) [[Cornell news]](https://news.cornell.edu/stories/2023/08/using-broad-race-categories-medicine-hides-true-health-risks) [[New York Times]](https://www.nytimes.com/interactive/2024/02/25/us/census-race-ethnicity-middle-east-north-africa.html)  

**Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers**   
Rajiv Movva\*, Sidhika Balachandar\*, Kenny Peng\*, Gabriel Agostini\*, Nikhil Garg, Emma Pierson.  
NAACL 2024.  
[[paper]](https://aclanthology.org/2024.naacl-long.67/) [[twitter]](https://twitter.com/rajivmovva/status/1683903070646960128) [[code]](https://github.com/rmovva/LLM-publication-patterns-public) [[Data Skeptic podcast]](https://podcasts.apple.com/au/podcast/arxiv-publication-patterns/id890348705?i=1000632314046)  

**Towards Intersectional, Feminist, Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection**   
Harini Suresh, Rajiv Movva, Amelia Dogan, Rahul Bhargava, Isadora Crux√™n, √Ångeles Martinez Cuba, Giulia Taurino, Wonyoung So, Catherine D‚ÄôIgnazio.  
FAccT 2022.  
üèÜ <span style="color:#CC5500">Best Student Paper</span> üèÜ  
[[paper]](https://dl.acm.org/doi/10.1145/3531146.3533132) [[twitter]](https://twitter.com/rajivmovva/status/1539172168269012992)  

**Dissecting Lottery Ticket Transformers: Structural and Behavorial Study of Sparse Neural Machine Translation**   
Rajiv Movva and Jason Zhao.  
BlackboxNLP @ EMNLP 2020.  
üèÜ <span style="color:#CC5500">Best Paper</span> üèÜ   
[[paper]](https://aclanthology.org/2020.blackboxnlp-1.19/) [[twitter]](https://twitter.com/rajivmovva/status/1311017289500766208) [[slides]](https://docs.google.com/presentation/d/1dVEXenyGF6Szxg8FPgua2sJQGWXvIdaBwKShS8jO8sM)  

**Deciphering regulatory DNA sequences and noncoding genetic variants using neural network models of massively parallel reporter assays**    
Rajiv Movva, Peyton Greenside, Georgi K Marinov, Surag Nair, Avanti Shrikumar, Anshul Kundaje.  
PLoS ONE, 2019.  
[[paper]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0218073) [[twitter]](https://twitter.com/rajivmovva/status/1030495776093294593)  